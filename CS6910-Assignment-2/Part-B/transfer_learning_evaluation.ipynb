{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "w0iYsN9gIPi4",
      "metadata": {
        "id": "w0iYsN9gIPi4"
      },
      "source": [
        "*For Part-B, we could not save the best model as done in part-A due to some WandB errors. Hence, we manually find the best model from the plots and re-train it and evaluate it on the test-set.* **Note**: We have **not** used the test-set till now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85669ff7",
      "metadata": {
        "id": "85669ff7"
      },
      "outputs": [],
      "source": [
        "# import statements\n",
        "from math import ceil\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow_addons.optimizers import RectifiedAdam, Lookahead\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.xception import Xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3f58142c",
      "metadata": {
        "id": "3f58142c"
      },
      "outputs": [],
      "source": [
        "# some fixed parameters\n",
        "# this code assumes that the dataset is in the same directory as the script\n",
        "# we fix the epochs as 5, as it takes really long for training\n",
        "BASE_PATH = \"./inaturalist_12K\"\n",
        "IMG_SIZE = (224, 224)\n",
        "EPOCHS = 5\n",
        "\n",
        "### BEST HYPERPARAMETERS ###\n",
        "BASE_MODEL = InceptionResNetV2(include_top=False, weights='imagenet', input_shape=(*IMG_SIZE, 3))\n",
        "BATCH_SIZE = 64\n",
        "FREEZE = 0.66\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "DATA_AUGMENTATION = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "50a07b6f",
      "metadata": {
        "id": "50a07b6f"
      },
      "outputs": [],
      "source": [
        "# a function for reading data from the given directory structure\n",
        "# we put aside 10% data for validation and  rescale our image pixel values by 1/255\n",
        "# returns the train, validation and test generators which can be passed to the model.fit()/model.evaluate() method\n",
        "def get_data_generators(data_augmentation=True, batch_size=32, img_size=IMG_SIZE):\n",
        "    if data_augmentation:\n",
        "        # the following augmentation techniques are used\n",
        "        data = ImageDataGenerator(rescale=1/255,\n",
        "                                  samplewise_center=True,\n",
        "                                  samplewise_std_normalization=True,\n",
        "                                  validation_split=0.1,\n",
        "                                  shear_range=0.25,\n",
        "                                  zoom_range=[0.25, 1.25],\n",
        "                                  width_shift_range=0.25,\n",
        "                                  height_shift_range=0.25,\n",
        "                                  horizontal_flip=True,\n",
        "                                  rotation_range=60)\n",
        "    else:\n",
        "        data = ImageDataGenerator(rescale=1/255,\n",
        "                                  validation_split=0.1)\n",
        "        \n",
        "    # this time read the test-data as well\n",
        "    # but for evaluation we do not do any augmentation on the test data\n",
        "    test_data = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    # here the class_mode is specified as sparse\n",
        "    # this means the targets are specified as whole numbers (ex. 0, 1, 2 etc) instead of one-hot vectors\n",
        "    # it is bit memory efficient this way\n",
        "    train_gen = data.flow_from_directory(f\"{BASE_PATH}/train\",\n",
        "                                         target_size=img_size,\n",
        "                                         batch_size=batch_size,\n",
        "                                         color_mode=\"rgb\",\n",
        "                                         class_mode=\"sparse\",\n",
        "                                         shuffle=True,\n",
        "                                         seed=123,\n",
        "                                         subset=\"training\")\n",
        "\n",
        "    validation_gen = data.flow_from_directory(f\"{BASE_PATH}/train\",\n",
        "                                              target_size=img_size,\n",
        "                                              batch_size=batch_size,\n",
        "                                              color_mode=\"rgb\",\n",
        "                                              class_mode=\"sparse\",\n",
        "                                              shuffle=True,\n",
        "                                              seed=123,\n",
        "                                              subset=\"validation\")\n",
        "    \n",
        "    test_gen = test_data.flow_from_directory(f\"{BASE_PATH}/val\",\n",
        "                                             target_size=img_size,\n",
        "                                             batch_size=batch_size,\n",
        "                                             color_mode=\"rgb\",\n",
        "                                             class_mode=\"sparse\",\n",
        "                                             shuffle=True,\n",
        "                                             seed=123)\n",
        "                                              \n",
        "    return train_gen, validation_gen, test_gen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7a2f74b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a2f74b1",
        "outputId": "f52ec628-98fb-4960-855a-314083d01eb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 9000 images belonging to 10 classes.\n",
            "Found 999 images belonging to 10 classes.\n",
            "Found 2000 images belonging to 10 classes.\n"
          ]
        }
      ],
      "source": [
        "# get the train, validation and test data\n",
        "train_gen, validation_gen, test_gen = get_data_generators(DATA_AUGMENTATION, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7528947d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7528947d",
        "outputId": "8cbdbcf8-a33f-46c7-bb41-4fc6a6f781c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "141/141 [==============================] - 161s 794ms/step - loss: 1.9167 - accuracy: 0.3954 - val_loss: 1.0743 - val_accuracy: 0.7247\n",
            "Epoch 2/5\n",
            "141/141 [==============================] - 106s 745ms/step - loss: 0.8892 - accuracy: 0.7517 - val_loss: 0.7265 - val_accuracy: 0.7828\n",
            "Epoch 3/5\n",
            "141/141 [==============================] - 105s 744ms/step - loss: 0.5652 - accuracy: 0.8217 - val_loss: 0.6478 - val_accuracy: 0.7848\n",
            "Epoch 4/5\n",
            "141/141 [==============================] - 105s 744ms/step - loss: 0.3765 - accuracy: 0.8820 - val_loss: 0.6535 - val_accuracy: 0.7938\n",
            "Epoch 5/5\n",
            "141/141 [==============================] - 105s 739ms/step - loss: 0.2134 - accuracy: 0.9346 - val_loss: 0.6902 - val_accuracy: 0.8028\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdb2223a990>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# freeze the specified fraction of layers\n",
        "# by setting their trainable variable to False\n",
        "# by default, all layers have trainable set as True\n",
        "N = len(BASE_MODEL.layers)\n",
        "for layer in BASE_MODEL.layers[: ceil(FREEZE*N)]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# build the model\n",
        "model = Sequential()\n",
        "model.add(BASE_MODEL)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(1024, activation=\"swish\"))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# we use a new optimizer Lookahead + Radam (a.k.a RANGER) with specified learning_rate and weight_decay\n",
        "# this optimizer has proved to converge really fast and generalize well\n",
        "# given the limited number of epochs we were able to make, we tried to use the most efficient optimizer to get the best results\n",
        "OPTIM = Lookahead(RectifiedAdam(learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY, amsgrad=True))\n",
        "model.compile(optimizer=OPTIM, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "# define the early stopping\n",
        "# we stop the training if the val_accuracy drops (by 1e-4 or higher) continuously for 4 times\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', min_delta=1e-4, patience=4, restore_best_weights=True)\n",
        "# fit the data to the model\n",
        "model.fit(train_gen, epochs=EPOCHS, validation_data=validation_gen, callbacks=[early_stop])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "u2_9yOdKKJ94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2_9yOdKKJ94",
        "outputId": "199e9a7a-bc42-41a6-eb2f-a7586eb2a6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 22s 669ms/step - loss: 0.6721 - accuracy: 0.8100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.6721240282058716, 0.8100000023841858]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now, evaluate the model on the test data\n",
        "model.evaluate(test_gen)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "transfer_learning_evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
