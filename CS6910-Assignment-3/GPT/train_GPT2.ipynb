{"cells":[{"cell_type":"markdown","metadata":{"id":"C5U6L7WFOaUT"},"source":["# To train the GPT, please upload this notebook and the ```run_clm.py``` script in google drive so that they are in the same directory. Then enable TPU in the notebook settings and run all cells."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":87507,"status":"ok","timestamp":1651078235306,"user":{"displayName":"Colab DeepLearning","userId":"13455794436727677803"},"user_tz":-330},"id":"sHct9vdDAejw","outputId":"bf66ee75-5bc4-46e5-a953-c4cfb1748c11"},"outputs":[],"source":["# pip install required packages\n","!pip install transformers datasets accelerate\n","!pip install cloud-tpu-client==0.10 torch==1.11.0 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-1.11-cp37-cp37m-linux_x86_64.whl\n","\n","# import statements\n","import os\n","from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n","import torch_xla\n","assert os.environ['COLAB_TPU_ADDR']\n","from random import randint"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":847349,"status":"ok","timestamp":1651079082651,"user":{"displayName":"Colab DeepLearning","userId":"13455794436727677803"},"user_tz":-330},"id":"zHPo4IzcA9pW","outputId":"d04dcca2-c3d8-4970-8859-66628f85e19d"},"outputs":[],"source":["# run the GPT2 model with required flags\n","# uses perplexity as the metric to evaluate the model\n","\n","!python3 run_clm.py \\\n","--model_type gpt2 \\\n","--model_name_or_path gpt2 \\\n","--train_file \"songs_merged.txt\" \\\n","--validation_file \"rihanna.txt\" \\\n","--per_device_train_batch_size 4 \\\n","--per_device_eval_batch_size 4 \\\n","--num_train_epochs 3 \\\n","--output_dir \"./gpt\" \\\n","--learning_rate 0.00001 \\"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51321,"status":"ok","timestamp":1651085207142,"user":{"displayName":"Colab DeepLearning","userId":"13455794436727677803"},"user_tz":-330},"id":"HDq1hXNGBy2j","outputId":"f7cea836-e8cd-49e4-9a61-7b10d9ed9e82"},"outputs":[],"source":["# use the trained model for predictions\n","model = TFGPT2LMHeadModel.from_pretrained(\"./gpt\", from_pt=True)\n","tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n","\n","# give the first input for the model to start predictions\n","input_ids = tokenizer.encode(\"I love deep learning,\", return_tensors='tf')\n","\n","# generate all outputs using beam-search\n","beam_output = model.generate(input_ids, \n","                             max_length=150, \n","                             num_return_sequences=1,\n","                             no_repeat_ngram_size=2,\n","                             repetition_penalty=2.5,\n","                             temperature=0.85,\n","                             do_sample=True,\n","                             top_k=0,\n","                             num_beams=5, \n","                             early_stopping=True)\n","\n","# in the beam outputs, find the longest prediction\n","output = sorted(beam_output, key=len, reverse=True)\n","\n","# save the longest prediction to a file\n","with open(\"final_song.txt\", \"w\") as f:\n","    f.writelines([tokenizer.decode(x, skip_special_tokens=True) for x in output])"]}],"metadata":{"accelerator":"TPU","colab":{"authorship_tag":"ABX9TyNzIXfk+OMSCAH7enppQBGf","background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"train_GPT2.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
